
@article{trapeau_fast_2016,
	title = {Fast and persistent adaptation to new spectral cues for sound localization suggests a many-to-one mapping mechanism},
	volume = {140},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/140/2/879/663968/Fast-and-persistent-adaptation-to-new-spectral},
	doi = {10.1121/1.4960568},
	abstract = {The adult human auditory system can adapt to changes in spectral cues for sound localization. This plasticity was demonstrated by changing the shape of the pinna with earmolds. Previous results indicate that participants regain localization accuracy after several weeks of adaptation and that the adapted state is retained for at least one week without earmolds. No aftereffect was observed after mold removal, but any aftereffect may be too short to be observed when responses are averaged over many trials. This work investigated the lack of aftereffect by analyzing single-trial responses and modifying visual, auditory, and tactile information during the localization task. Results showed that participants localized accurately immediately after mold removal, even at the first stimulus presentation. Knowledge of the stimulus spectrum, tactile information about the absence of the earmolds, and visual feedback were not necessary to localize accurately after adaptation. Part of the adaptation persisted for one month without molds. The results are consistent with the hypothesis of a many-to-one mapping of the spectral cues, in which several spectral profiles are simultaneously associated with one sound location. Additionally, participants with acoustically more informative spectral cues localized sounds more accurately, and larger acoustical disturbances by the molds reduced adaptation success.},
	language = {en},
	number = {2},
	urldate = {2023-12-12},
	journal = {The Journal of the Acoustical Society of America},
	author = {Trapeau, Régis and Aubrais, Valérie and Schönwiesner, Marc},
	month = aug,
	year = {2016},
	pages = {879--890},
	file = {Trapeau et al. - 2016 - Fast and persistent adaptation to new spectral cue.pdf:/Users/paulfriedrich/Zotero/storage/LE5ASMAA/Trapeau et al. - 2016 - Fast and persistent adaptation to new spectral cue.pdf:application/pdf},
}

@article{hofman_relearning_1998,
	title = {Relearning sound localization with new ears},
	volume = {1},
	language = {en},
	number = {5},
	journal = {nature neuroscience},
	author = {Hofman, Paul M},
	year = {1998},
	file = {Hofman - 1998 - Relearning sound localization with new ears.pdf:/Users/paulfriedrich/Zotero/storage/9VNQY4SF/Hofman - 1998 - Relearning sound localization with new ears.pdf:application/pdf},
}

@article{middlebrooks_individual_1999,
	title = {Individual differences in external-ear transfer functions reduced by scaling in frequency},
	volume = {106},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/106/3/1480/553209/Individual-differences-in-external-ear-transfer},
	doi = {10.1121/1.427176},
	abstract = {This study examined inter-subject differences in the transfer functions from the free field to the human ear canal, which are commonly know as head-related transfer functions. The directional components of such transfer functions are referred here to as directional transfer functions (DTFs). The DTFs of 45 subjects varied systematically among subjects in regard to the frequencies of spectral features such as peaks and notches. Inter-subject spectral differences in DTFs were quantified between 3.7 and 12.9 kHz for sound-source directions throughout the coordinate sphere. For each pair of subjects, an optimal frequency scale factor aligned spectral features between subjects and, thus, minimized inter-subject spectral differences. Frequency scaling of DTFs reduced spectral differences by a median value of 15.5\% across all pairs of subjects and by more than half in 9.5\% of subject pairs. Optimal scale factors showed a median value of 1.061 and a maximum of 1.38. The optimal scale factor between any pair of subjects correlated highly with the ratios of subjects’ maximum interaural delays, sizes of their external ears, and widths of their heads.},
	language = {en},
	number = {3},
	urldate = {2023-12-12},
	journal = {The Journal of the Acoustical Society of America},
	author = {Middlebrooks, John C.},
	month = sep,
	year = {1999},
	pages = {1480--1492},
	file = {Middlebrooks - 1999 - Individual differences in external-ear transfer fu.pdf:/Users/paulfriedrich/Zotero/storage/MD4UVQEV/Middlebrooks - 1999 - Individual differences in external-ear transfer fu.pdf:application/pdf},
}

@article{wanrooij_relearning_2005,
	title = {Relearning {Sound} {Localization} with a {New} {Ear}},
	volume = {25},
	copyright = {Copyright © 2005 Society for Neuroscience 0270-6474/05/255413-12.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/25/22/5413},
	doi = {10.1523/JNEUROSCI.0850-05.2005},
	abstract = {Human sound localization results primarily from the processing of binaural differences in sound level and arrival time for locations in the horizontal plane (azimuth) and of spectral shape cues generated by the head and pinnae for positions in the vertical plane (elevation). The latter mechanism incorporates two processing stages: a spectral-to-spatial mapping stage and a binaural weighting stage that determines the contribution of each ear to perceived elevation as function of sound azimuth. We demonstrated recently that binaural pinna molds virtually abolish the ability to localize sound-source elevation, but, after several weeks, subjects regained normal localization performance. It is not clear which processing stage underlies this remarkable plasticity, because the auditory system could have learned the new spectral cues separately for each ear (spatial-mapping adaptation) or for one ear only, while extending its contribution into the contralateral hemifield (binaural-weighting adaptation). To dissociate these possibilities, we applied a long-term monaural spectral perturbation in 13 subjects. Our results show that, in eight experiments, listeners learned to localize accurately with new spectral cues that differed substantially from those provided by their own ears. Interestingly, five subjects, whose spectral cues were not sufficiently perturbed, never yielded stable localization performance. Our findings indicate that the analysis of spectral cues may involve a correlation process between the sensory input and a stored spectral representation of the subject's ears and that learning acts predominantly at a spectral-to-spatial mapping level rather than at the level of binaural weighting.},
	language = {en},
	number = {22},
	urldate = {2023-12-16},
	journal = {Journal of Neuroscience},
	author = {Wanrooij, Marc M. Van and Opstal, A. John Van},
	month = jun,
	year = {2005},
	pmid = {15930391},
	note = {Publisher: Society for Neuroscience
Section: Behavioral/Systems/Cognitive},
	keywords = {directional hearing, human, monaural, pinna, plasticity, spectral cues},
	pages = {5413--5424},
	file = {Full Text PDF:/Users/paulfriedrich/Zotero/storage/XWUAKE23/Wanrooij and Opstal - 2005 - Relearning Sound Localization with a New Ear.pdf:application/pdf},
}

@article{schonwiesner_soundlab_2021,
	title = {s(ound)lab: {An} easy to learn {Python} package for designing and running psychoacoustic experiments.},
	volume = {6},
	issn = {2475-9066},
	shorttitle = {s(ound)lab},
	url = {https://joss.theoj.org/papers/10.21105/joss.03284},
	doi = {10.21105/joss.03284},
	abstract = {Slab enables researchers and students to prototype and implement psychoacoustic experiments quickly. Slab implements many of the procedures for psychoacoustic research and experiment control and is easily combined with other Python software. A secondary aim of slab is to enable researchers and students without prior training in computer programming and digital signal processing to implement and conduct these experiments. Slab provides building blocks rather than ready-made solutions, so that experimenters still need to carefully consider stimulation, sequencing and data management. This also makes slab very flexible and easy to customise. In the documentation (see slab.readthedocs.io), we provide tutorials suitable for beginners. We also provide experiments conducted in our lab as worked examples.},
	language = {en},
	number = {62},
	urldate = {2023-12-29},
	journal = {Journal of Open Source Software},
	author = {Schönwiesner, Marc and Bialas, Ole},
	month = jun,
	year = {2021},
	pages = {3284},
	file = {Schönwiesner and Bialas - 2021 - s(ound)lab An easy to learn Python package for de.pdf:/Users/paulfriedrich/Zotero/storage/2NDZIXJJ/Schönwiesner and Bialas - 2021 - s(ound)lab An easy to learn Python package for de.pdf:application/pdf},
}

@article{ward_stimulus_1979,
	title = {Stimulus {Information} and {Sequential} {Dependencies} in {Magnitude} {Estimation} and {Cross}-{Modality} {Matching}},
	volume = {5},
	language = {en},
	number = {3},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Ward, Lawrence M},
	year = {1979},
	pages = {444--459},
	file = {Ward - Stimulus Information and Sequential Dependencies i.pdf:/Users/paulfriedrich/Zotero/storage/NKVPDAHN/Ward - Stimulus Information and Sequential Dependencies i.pdf:application/pdf},
}

@article{andeol_sound_2013,
	title = {Sound localization in noise and sensitivity to spectral shape},
	volume = {304},
	issn = {03785955},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378595513001445},
	doi = {10.1016/j.heares.2013.06.001},
	abstract = {Individual differences exist in sound localization performance even for normal-hearing listeners. Some of these differences might be related to acoustical differences in localization cues carried by the head related transfer functions (HRTF). Recent data suggest that individual differences in sound localization performance could also have a perceptual origin. The localization of an auditory target in the up/down and front/back dimensions requires the analysis of the spectral shape of the stimulus. In the present study, we investigated the role of an acoustic factor, the prominence of the spectral shape (“spectral strength”) and the role of a perceptual factor, the listener’s sensitivity to spectral shape, in individual differences observed in sound localization performance. Spectral strength was computed as the spectral distance between the magnitude spectrum of the HRTFs and a ﬂat spectrum. Sensitivity to spectral shape was evaluated using spectral-modulation thresholds measured with a broadband (0.2e12.8 kHz) or highfrequency (4e16 kHz) carrier and for different spectral modulation frequencies (below 1 cycle/octave, between 1 and 2 cycles/octave, above 2 cycles/octave). Data obtained from 19 young normal-hearing listeners showed that low thresholds for spectral modulation frequency below 1 cycle/octave with a high-frequency carrier were associated with better sound localization performance. No correlation was found between sound localization performance and the spectral strength of the HRTFs. These results suggest that differences in perceptual ability, rather than acoustical differences, contribute to individual differences in sound localization performance in noise.},
	language = {en},
	urldate = {2023-12-30},
	journal = {Hearing Research},
	author = {Andéol, Guillaume and Macpherson, Ewan A. and Sabin, Andrew T.},
	month = oct,
	year = {2013},
	pages = {20--27},
	file = {Andéol et al. - 2013 - Sound localization in noise and sensitivity to spe.pdf:/Users/paulfriedrich/Zotero/storage/3UC6Z8CL/Andéol et al. - 2013 - Sound localization in noise and sensitivity to spe.pdf:application/pdf},
}

@article{reiss_spectral_2005,
	title = {Spectral {Edge} {Sensitivity} in {Neural} {Circuits} of the {Dorsal} {Cochlear} {Nucleus}},
	volume = {25},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4963-04.2005},
	doi = {10.1523/JNEUROSCI.4963-04.2005},
	abstract = {One possible function of the dorsal cochlear nucleus (DCN) is discrimination of head-related transfer functions (HRTFs), spectral cues used for vertical sound localization. Recent psychophysical and physiological studies suggest that steep, rising spectral edges may be the features used to identify HRTFs. Here we showed, using notch noise and noise band stimuli presented over a range of frequencies, that a subclass of DCN type IV neurons responded with a response peak when the rising spectral edge of a notch or band was aligned near best frequency (BF). This edge sensitivity was correlated with weak or inhibited responses to broadband noise and inhibition in receptive fields at frequencies below BF. Some aspects of the inhibition shaping the response peak, namely inhibition to rising edges below BF and to falling edges at BF, could be explained by the properties of type II interneurons with BFs below those of the type IV neurons. However, many type IV neurons also showed inhibitory responses with the rising spectral edge just above BF, and these responses could not be reproduced by current models of DCN circuitry. Therefore, a new component of the DCN circuit is needed to fully explain the responses to rising spectral edges. This shaping of edge sensitivity by inhibition to rising spectral edges both below and above BF suggests the specialization of DCN for spectral edge coding along the tonotopic gradient.},
	language = {en},
	number = {14},
	urldate = {2024-01-11},
	journal = {The Journal of Neuroscience},
	author = {Reiss, Lina A. J. and Young, Eric D.},
	month = apr,
	year = {2005},
	pages = {3680--3691},
	file = {Reiss and Young - 2005 - Spectral Edge Sensitivity in Neural Circuits of th.pdf:/Users/paulfriedrich/Zotero/storage/EZDFQZTY/Reiss and Young - 2005 - Spectral Edge Sensitivity in Neural Circuits of th.pdf:application/pdf},
}

@article{langendijk_contribution_2002,
	title = {Contribution of spectral cues to human sound localization},
	volume = {112},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/112/4/1583/550090/Contribution-of-spectral-cues-to-human-sound},
	doi = {10.1121/1.1501901},
	abstract = {The contribution of spectral cues to human sound localization was investigated by removing cues in 12-, 1- or 2-octave bands in the frequency range above 4 kHz. Localization responses were given by placing an acoustic pointer at the same apparent position as a virtual target. The pointer was generated by filtering a 100-ms harmonic complex with equalized head-related transfer functions (HRTFs). Listeners controlled the pointer via a hand-held stick that rotated about a fixed point. In the baseline condition, the target, a 200-ms noise burst, was filtered with the same HRTFs as the pointer. In other conditions, the spectral information within a certain frequency band was removed by replacing the directional transfer function within this band with the average transfer of this band. Analysis of the data showed that removing cues in 12-octave bands did not affect localization, whereas for the 2-octave band correct localization was virtually impossible. The results obtained for the 1-octave bands indicate that up–down cues are located mainly in the 6–12-kHz band, and front–back cues in the 8–16-kHz band. The interindividual spread in response patterns suggests that different listeners use different localization cues. The response patterns in the median plane can be predicted using a model based on spectral comparison of directional transfer functions for target and response directions.},
	language = {en},
	number = {4},
	urldate = {2024-01-13},
	journal = {The Journal of the Acoustical Society of America},
	author = {Langendijk, Erno H. A. and Bronkhorst, Adelbert W.},
	month = oct,
	year = {2002},
	pages = {1583--1596},
	file = {Langendijk and Bronkhorst - 2002 - Contribution of spectral cues to human sound local.pdf:/Users/paulfriedrich/Zotero/storage/ZH3HR2W8/Langendijk and Bronkhorst - 2002 - Contribution of spectral cues to human sound local.pdf:application/pdf},
}

@article{davis_auditory_2003,
	title = {Auditory {Processing} of {Spectral} {Cues} for {Sound} {Localization} in the {Inferior} {Colliculus}},
	volume = {4},
	issn = {1525-3961, 1438-7573},
	url = {http://link.springer.com/10.1007/s10162-002-2002-5},
	doi = {10.1007/s10162-002-2002-5},
	abstract = {The head-related transfer function (HRTF) of the cat adds directionally dependent energy minima to the amplitude spectrum of complex sounds. These spectral notches are a principal cue for the localization of sound source elevation. Physiological evidence suggests that the dorsal cochlear nucleus (DCN) plays a critical role in the brainstem processing of this directional feature. Type O units in the central nucleus of the inferior colliculus (ICC) are a primary target of ascending DCN projections and, therefore, may represent midbrain specializations for the auditory processing of spectral cues for sound localization. Behavioral studies conﬁrm a loss of sound orientation accuracy when DCN projections to the inferior colliculus are surgically lesioned. This study used simple analogs of HRTF notches to characterize single-unit response patterns in the ICC of decerebrate cats that may contribute to the directional sensitivity of the brain’s spectral processing pathways. Manipulations of notch frequency and bandwidth demonstrated frequency-speciﬁc excitatory responses that have the capacity to encode HRTF-based cues for sound source location. These response patterns were limited to type O units in the ICC and have not been observed for the projection neurons of the DCN. The unique spectral integration properties of type O units suggest that DCN inﬂuences are transformed into a more selective representation of sound source location by a local convergence of wideband excitatory and frequency-tuned inhibitory inputs.},
	language = {en},
	number = {2},
	urldate = {2024-01-13},
	journal = {JARO - Journal of the Association for Research in Otolaryngology},
	author = {Davis, Kevin A. and Ramachandran, Ramnarayan and May, Bradford J.},
	month = jun,
	year = {2003},
	pages = {148--163},
	file = {Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:/Users/paulfriedrich/Zotero/storage/6PAJNQMK/Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:application/pdf},
}

@article{algazi_elevation_2001,
	title = {Elevation localization and head-related transfer function analysis at low frequencies},
	volume = {109},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/109/3/1110/553520/Elevation-localization-and-head-related-transfer},
	doi = {10.1121/1.1349185},
	abstract = {Monaural spectral features due to pinna diffraction are the primary cues for elevation. Because these features appear above 3 kHz where the wavelength becomes comparable to pinna size, it is generally believed that accurate elevation estimation requires wideband sources. However, psychoacoustic tests show that subjects can estimate elevation for low-frequency sources. In the experiments reported, random noise bursts low-pass filtered to 3 kHz were processed with individualized head-related transfer functions (HRTFs), and six subjects were asked to report the elevation angle around four cones of confusion. The accuracy in estimating elevation was degraded when compared to a baseline test with wideband stimuli. The reduction in performance was a function of azimuth and was highest in the median plane. However, when the source was located away from the median plane, subjects were able to estimate elevation, often with surprisingly good accuracy. Analysis of the HRTFs reveals the existence of elevation-dependent features at low frequencies. The physical origin of the low-frequency features is attributed primarily to head diffraction and torso reflections. It is shown that simple geometrical approximations and models of the head and torso explain these low-frequency features and the corresponding elevations cues.},
	language = {en},
	number = {3},
	urldate = {2024-01-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Algazi, V. Ralph and Avendano, Carlos and Duda, Richard O.},
	month = mar,
	year = {2001},
	pages = {1110--1122},
	file = {Algazi et al. - 2001 - Elevation localization and head-related transfer f.pdf:/Users/paulfriedrich/Zotero/storage/KBJV8XWX/Algazi et al. - 2001 - Elevation localization and head-related transfer f.pdf:application/pdf},
}

@article{asano_role_1990,
	title = {Role of spectral cues in median plane localization},
	volume = {88},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/88/1/159/626776/Role-of-spectral-cues-in-median-plane},
	doi = {10.1121/1.399963},
	abstract = {The role of spectral cues in the sound source to ear transfer function in median plane sound localization is investigated in this paper. At first, transfer functions were measured and analyzed. Then, these transfer functions were used in experiments where sounds from a source on the median plane were simulated and presented to subjects through headphones. In these simulation experiments, the transfer functions were smoothed by ARMA models with different degrees of simplification to investigate the role of microscopic and macroscopic patterns in the transfer functions for median plane localization. The results of the study are summarized as follows: (1) For front–rear judgment, information derived from microscopic peaks and dips in the low-frequency region (below 2 kHz) and the macroscopic patterns in the high-frequency region seems to be utilized; (2) for judgment of elevation angle, major cues exist in the high-frequency region above 5 kHz. The information in macroscopic patterns is utilized instead of that in small peaks and dips.},
	language = {en},
	number = {1},
	urldate = {2024-01-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Asano, Futoshi and Suzuki, Yoiti and Sone, Toshio},
	month = jul,
	year = {1990},
	pages = {159--168},
	file = {Asano et al. - 1990 - Role of spectral cues in median plane localization.pdf:/Users/paulfriedrich/Zotero/storage/2Q9XQ8PW/Asano et al. - 1990 - Role of spectral cues in median plane localization.pdf:application/pdf},
}

@article{carlile_relearning_2014,
	title = {Relearning {Auditory} {Spectral} {Cues} for {Locations} {Inside} and {Outside} the {Visual} {Field}},
	volume = {15},
	issn = {1525-3961, 1438-7573},
	url = {http://link.springer.com/10.1007/s10162-013-0429-5},
	doi = {10.1007/s10162-013-0429-5},
	language = {en},
	number = {2},
	urldate = {2024-01-18},
	journal = {Journal of the Association for Research in Otolaryngology},
	author = {Carlile, Simon and Blackman, Toby},
	month = apr,
	year = {2014},
	pages = {249--263},
	file = {Carlile and Blackman - 2014 - Relearning Auditory Spectral Cues for Locations In.pdf:/Users/paulfriedrich/Zotero/storage/G65CWZWA/Carlile and Blackman - 2014 - Relearning Auditory Spectral Cues for Locations In.pdf:application/pdf},
}

@article{hofman_spectro-temporal_1998,
	title = {Spectro-temporal factors in two-dimensional human sound localization},
	volume = {103},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/103/5/2634/557650/Spectro-temporal-factors-in-two-dimensional-human},
	doi = {10.1121/1.422784},
	abstract = {This paper describes the effect of spectro-temporal factors on human sound localization performance in two dimensions (2D). Subjects responded with saccadic eye movements to acoustic stimuli presented in the frontal hemisphere. Both the horizontal (azimuth) and vertical (elevation) stimulus location were varied randomly. Three types of stimuli were used, having different spectro-temporal patterns, but identically shaped broadband averaged power spectra: noise bursts, frequency-modulated tones, and trains of short noise bursts. In all subjects, the elevation components of the saccadic responses varied systematically with the different temporal parameters, whereas the azimuth response components remained equally accurate for all stimulus conditions. The data show that the auditory system does not calculate a final elevation estimate from a long-term (order 100 ms) integration of sensory input. Instead, the results suggest that the auditory system may apply a “multiple-look” strategy in which the final estimate is calculated from consecutive short-term (order few ms) estimates. These findings are incorporated in a conceptual model that accounts for the data and proposes a scheme for the temporal processing of spectral sensory information into a dynamic estimate of sound elevation.},
	language = {en},
	number = {5},
	urldate = {2024-01-18},
	journal = {The Journal of the Acoustical Society of America},
	author = {Hofman, Paul M. and Van Opstal, A. John},
	month = may,
	year = {1998},
	pages = {2634--2648},
	file = {Hofman and Van Opstal - 1998 - Spectro-temporal factors in two-dimensional human .pdf:/Users/paulfriedrich/Zotero/storage/3X92HS68/Hofman and Van Opstal - 1998 - Spectro-temporal factors in two-dimensional human .pdf:application/pdf},
}

@article{davis_auditory_2003-1,
	title = {Auditory {Processing} of {Spectral} {Cues} for {Sound} {Localization} in the {Inferior} {Colliculus}},
	volume = {4},
	issn = {1525-3961, 1438-7573},
	url = {http://link.springer.com/10.1007/s10162-002-2002-5},
	doi = {10.1007/s10162-002-2002-5},
	abstract = {The head-related transfer function (HRTF) of the cat adds directionally dependent energy minima to the amplitude spectrum of complex sounds. These spectral notches are a principal cue for the localization of sound source elevation. Physiological evidence suggests that the dorsal cochlear nucleus (DCN) plays a critical role in the brainstem processing of this directional feature. Type O units in the central nucleus of the inferior colliculus (ICC) are a primary target of ascending DCN projections and, therefore, may represent midbrain specializations for the auditory processing of spectral cues for sound localization. Behavioral studies conﬁrm a loss of sound orientation accuracy when DCN projections to the inferior colliculus are surgically lesioned. This study used simple analogs of HRTF notches to characterize single-unit response patterns in the ICC of decerebrate cats that may contribute to the directional sensitivity of the brain’s spectral processing pathways. Manipulations of notch frequency and bandwidth demonstrated frequency-speciﬁc excitatory responses that have the capacity to encode HRTF-based cues for sound source location. These response patterns were limited to type O units in the ICC and have not been observed for the projection neurons of the DCN. The unique spectral integration properties of type O units suggest that DCN inﬂuences are transformed into a more selective representation of sound source location by a local convergence of wideband excitatory and frequency-tuned inhibitory inputs.},
	language = {en},
	number = {2},
	urldate = {2024-01-18},
	journal = {JARO - Journal of the Association for Research in Otolaryngology},
	author = {Davis, Kevin A. and Ramachandran, Ramnarayan and May, Bradford J.},
	month = jun,
	year = {2003},
	pages = {148--163},
	file = {Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:/Users/paulfriedrich/Zotero/storage/ZDBJKIPI/Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:application/pdf},
}

@article{king_spatial_1987,
	title = {Spatial response properties of acoustically responsive neurons in the superior colliculus of the ferret: a map of auditory space},
	volume = {57},
	issn = {0022-3077, 1522-1598},
	shorttitle = {Spatial response properties of acoustically responsive neurons in the superior colliculus of the ferret},
	url = {https://www.physiology.org/doi/10.1152/jn.1987.57.2.596},
	doi = {10.1152/jn.1987.57.2.596},
	abstract = {Extracellular single-unit recordings were made from auditory neurons in the superior colliculus of ferrets anesthetized with either a neuroleptic or a combination of barbiturate with paralysis. The response properties of these neurons were studied using white-noise bursts presented under free-field conditions in an anechoic chamber. Auditory neurons were found throughout the intermediate and deep layers of the superior colliculus. All neurons were spontaneously active, the rates of discharge varying from 0.1 to 61.1 spikes X s-1. Although the spontaneous discharge interspike-interval histograms for many units approximated to exponential distributions, the histograms of 44\% had clear secondary peaks, indicating more than one preferred interval, and could not be modeled by a simple process. Most neurons (50\%) responded only at stimulus onset, whereas 12\% exhibited sustained discharges and 38\% gave onset responses followed by a period of silence or reduced activity and then a period of elevated discharge, which was not apparently related to stimulus offset. Neurons with multipeaked response patterns were concentrated in the stratum griseum profundum. The latencies from arrival of the stimulus at the ear to the onset of neural activity ranged from 6 to 49 ms and decreased with increasing stimulus intensity. Although responsive to sounds over a large region of space, most neurons had clearly defined best positions at which the strongest response was obtained. The response declined as the speaker was moved away from this position, and nearly all units had peaked response profiles. The spatial tuning varied between different neurons, but most were more sharply tuned in elevation than in azimuth. Increasing the stimulus intensity did not, in general, alter the best positions of these neurons, but usually resulted in a broadening of the receptive fields, although other units became more sharply tuned. The best positions of auditory neurons varied systematically in azimuth from 20 degrees into the ipsilateral hemifield to 130 degrees into the contralateral hemifield as the electrode was moved from the rostrolateral to the caudomedial end of the superior colliculus. The best positions shifted in elevation along a rostromedial to caudolateral axis from 60 degrees above to 50 degrees below the visuoaural plane.(ABSTRACT TRUNCATED AT 400 WORDS)},
	language = {en},
	number = {2},
	urldate = {2024-01-18},
	journal = {Journal of Neurophysiology},
	author = {King, A. J. and Hutchings, M. E.},
	month = feb,
	year = {1987},
	pages = {596--624},
	file = {King and Hutchings - 1987 - Spatial response properties of acoustically respon.pdf:/Users/paulfriedrich/Zotero/storage/RYBX9HVD/King and Hutchings - 1987 - Spatial response properties of acoustically respon.pdf:application/pdf},
}

@article{trapeau_encoding_2018,
	title = {The {Encoding} of {Sound} {Source} {Elevation} in the {Human} {Auditory} {Cortex}},
	volume = {38},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2530-17.2018},
	doi = {10.1523/JNEUROSCI.2530-17.2018},
	abstract = {Spatial hearing is a crucial capacity of the auditory system. While the encoding of horizontal sound direction has been extensively studied, very little is known about the representation of vertical sound direction in the auditory cortex. Using high-resolution fMRI, we measured voxelwise sound elevation tuning curves in human auditory cortex and show that sound elevation is represented by broad tuning functions preferring lower elevations as well as secondary narrow tuning functions preferring individual elevation directions. We changed the ear shape of participants (male and female) with silicone molds for several days. This manipulation reduced or abolished the ability to discriminate sound elevation and flattened cortical tuning curves. Tuning curves recovered their original shape as participants adapted to the modified ears and regained elevation perception over time. These findings suggest that the elevation tuning observed in low-level auditory cortex did not arise from the physical features of the stimuli but is contingent on experience with spectral cues and covaries with the change in perception. One explanation for this observation may be that the tuning in low-level auditory cortex underlies the subjective perception of sound elevation.
            
              SIGNIFICANCE STATEMENT
              This study addresses two fundamental questions about the brain representation of sensory stimuli: how the vertical spatial axis of auditory space is represented in the auditory cortex and whether low-level sensory cortex represents physical stimulus features or subjective perceptual attributes. Using high-resolution fMRI, we show that vertical sound direction is represented by broad tuning functions preferring lower elevations as well as secondary narrow tuning functions preferring individual elevation directions. In addition, we demonstrate that the shape of these tuning functions is contingent on experience with spectral cues and covaries with the change in perception, which may indicate that the tuning functions in low-level auditory cortex underlie the perceived elevation of a sound source.},
	language = {en},
	number = {13},
	urldate = {2024-01-18},
	journal = {The Journal of Neuroscience},
	author = {Trapeau, Régis and Schönwiesner, Marc},
	month = mar,
	year = {2018},
	pages = {3252--3264},
	file = {Trapeau and Schönwiesner - 2018 - The Encoding of Sound Source Elevation in the Huma.pdf:/Users/paulfriedrich/Zotero/storage/PQEIDDTX/Trapeau and Schönwiesner - 2018 - The Encoding of Sound Source Elevation in the Huma.pdf:application/pdf},
}
