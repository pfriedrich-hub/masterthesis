
@article{trapeau_fast_2016,
	title = {Fast and persistent adaptation to new spectral cues for sound localization suggests a many-to-one mapping mechanism},
	volume = {140},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/140/2/879/663968/Fast-and-persistent-adaptation-to-new-spectral},
	doi = {10.1121/1.4960568},
	abstract = {The adult human auditory system can adapt to changes in spectral cues for sound localization. This plasticity was demonstrated by changing the shape of the pinna with earmolds. Previous results indicate that participants regain localization accuracy after several weeks of adaptation and that the adapted state is retained for at least one week without earmolds. No aftereffect was observed after mold removal, but any aftereffect may be too short to be observed when responses are averaged over many trials. This work investigated the lack of aftereffect by analyzing single-trial responses and modifying visual, auditory, and tactile information during the localization task. Results showed that participants localized accurately immediately after mold removal, even at the first stimulus presentation. Knowledge of the stimulus spectrum, tactile information about the absence of the earmolds, and visual feedback were not necessary to localize accurately after adaptation. Part of the adaptation persisted for one month without molds. The results are consistent with the hypothesis of a many-to-one mapping of the spectral cues, in which several spectral profiles are simultaneously associated with one sound location. Additionally, participants with acoustically more informative spectral cues localized sounds more accurately, and larger acoustical disturbances by the molds reduced adaptation success.},
	language = {en},
	number = {2},
	urldate = {2023-12-12},
	journal = {The Journal of the Acoustical Society of America},
	author = {Trapeau, Régis and Aubrais, Valérie and Schönwiesner, Marc},
	month = aug,
	year = {2016},
	pages = {879--890},
	file = {Trapeau et al. - 2016 - Fast and persistent adaptation to new spectral cue.pdf:/Users/paulfriedrich/Zotero/storage/LE5ASMAA/Trapeau et al. - 2016 - Fast and persistent adaptation to new spectral cue.pdf:application/pdf},
}

@article{hofman_relearning_1998,
	title = {Relearning sound localization with new ears},
	volume = {1},
	language = {en},
	number = {5},
	journal = {nature neuroscience},
	author = {Hofman, Paul M},
	year = {1998},
	file = {Hofman - 1998 - Relearning sound localization with new ears.pdf:/Users/paulfriedrich/Zotero/storage/9VNQY4SF/Hofman - 1998 - Relearning sound localization with new ears.pdf:application/pdf},
}

@article{middlebrooks_individual_1999,
	title = {Individual differences in external-ear transfer functions reduced by scaling in frequency},
	volume = {106},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/106/3/1480/553209/Individual-differences-in-external-ear-transfer},
	doi = {10.1121/1.427176},
	abstract = {This study examined inter-subject differences in the transfer functions from the free field to the human ear canal, which are commonly know as head-related transfer functions. The directional components of such transfer functions are referred here to as directional transfer functions (DTFs). The DTFs of 45 subjects varied systematically among subjects in regard to the frequencies of spectral features such as peaks and notches. Inter-subject spectral differences in DTFs were quantified between 3.7 and 12.9 kHz for sound-source directions throughout the coordinate sphere. For each pair of subjects, an optimal frequency scale factor aligned spectral features between subjects and, thus, minimized inter-subject spectral differences. Frequency scaling of DTFs reduced spectral differences by a median value of 15.5\% across all pairs of subjects and by more than half in 9.5\% of subject pairs. Optimal scale factors showed a median value of 1.061 and a maximum of 1.38. The optimal scale factor between any pair of subjects correlated highly with the ratios of subjects’ maximum interaural delays, sizes of their external ears, and widths of their heads.},
	language = {en},
	number = {3},
	urldate = {2023-12-12},
	journal = {The Journal of the Acoustical Society of America},
	author = {Middlebrooks, John C.},
	month = sep,
	year = {1999},
	pages = {1480--1492},
	file = {Middlebrooks - 1999 - Individual differences in external-ear transfer fu.pdf:/Users/paulfriedrich/Zotero/storage/MD4UVQEV/Middlebrooks - 1999 - Individual differences in external-ear transfer fu.pdf:application/pdf},
}

@article{wanrooij_relearning_2005,
	title = {Relearning {Sound} {Localization} with a {New} {Ear}},
	volume = {25},
	copyright = {Copyright © 2005 Society for Neuroscience 0270-6474/05/255413-12.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/25/22/5413},
	doi = {10.1523/JNEUROSCI.0850-05.2005},
	abstract = {Human sound localization results primarily from the processing of binaural differences in sound level and arrival time for locations in the horizontal plane (azimuth) and of spectral shape cues generated by the head and pinnae for positions in the vertical plane (elevation). The latter mechanism incorporates two processing stages: a spectral-to-spatial mapping stage and a binaural weighting stage that determines the contribution of each ear to perceived elevation as function of sound azimuth. We demonstrated recently that binaural pinna molds virtually abolish the ability to localize sound-source elevation, but, after several weeks, subjects regained normal localization performance. It is not clear which processing stage underlies this remarkable plasticity, because the auditory system could have learned the new spectral cues separately for each ear (spatial-mapping adaptation) or for one ear only, while extending its contribution into the contralateral hemifield (binaural-weighting adaptation). To dissociate these possibilities, we applied a long-term monaural spectral perturbation in 13 subjects. Our results show that, in eight experiments, listeners learned to localize accurately with new spectral cues that differed substantially from those provided by their own ears. Interestingly, five subjects, whose spectral cues were not sufficiently perturbed, never yielded stable localization performance. Our findings indicate that the analysis of spectral cues may involve a correlation process between the sensory input and a stored spectral representation of the subject's ears and that learning acts predominantly at a spectral-to-spatial mapping level rather than at the level of binaural weighting.},
	language = {en},
	number = {22},
	urldate = {2023-12-16},
	journal = {Journal of Neuroscience},
	author = {Wanrooij, Marc M. Van and Opstal, A. John Van},
	month = jun,
	year = {2005},
	pmid = {15930391},
	note = {Publisher: Society for Neuroscience
Section: Behavioral/Systems/Cognitive},
	keywords = {directional hearing, human, monaural, pinna, plasticity, spectral cues},
	pages = {5413--5424},
	file = {Full Text PDF:/Users/paulfriedrich/Zotero/storage/XWUAKE23/Wanrooij and Opstal - 2005 - Relearning Sound Localization with a New Ear.pdf:application/pdf},
}

@article{schonwiesner_soundlab_2021,
	title = {s(ound)lab: {An} easy to learn {Python} package for designing and running psychoacoustic experiments.},
	volume = {6},
	issn = {2475-9066},
	shorttitle = {s(ound)lab},
	url = {https://joss.theoj.org/papers/10.21105/joss.03284},
	doi = {10.21105/joss.03284},
	abstract = {Slab enables researchers and students to prototype and implement psychoacoustic experiments quickly. Slab implements many of the procedures for psychoacoustic research and experiment control and is easily combined with other Python software. A secondary aim of slab is to enable researchers and students without prior training in computer programming and digital signal processing to implement and conduct these experiments. Slab provides building blocks rather than ready-made solutions, so that experimenters still need to carefully consider stimulation, sequencing and data management. This also makes slab very flexible and easy to customise. In the documentation (see slab.readthedocs.io), we provide tutorials suitable for beginners. We also provide experiments conducted in our lab as worked examples.},
	language = {en},
	number = {62},
	urldate = {2023-12-29},
	journal = {Journal of Open Source Software},
	author = {Schönwiesner, Marc and Bialas, Ole},
	month = jun,
	year = {2021},
	pages = {3284},
	file = {Schönwiesner and Bialas - 2021 - s(ound)lab An easy to learn Python package for de.pdf:/Users/paulfriedrich/Zotero/storage/2NDZIXJJ/Schönwiesner and Bialas - 2021 - s(ound)lab An easy to learn Python package for de.pdf:application/pdf},
}

@article{ward_stimulus_1979,
	title = {Stimulus {Information} and {Sequential} {Dependencies} in {Magnitude} {Estimation} and {Cross}-{Modality} {Matching}},
	volume = {5},
	language = {en},
	number = {3},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Ward, Lawrence M},
	year = {1979},
	pages = {444--459},
	file = {Ward - Stimulus Information and Sequential Dependencies i.pdf:/Users/paulfriedrich/Zotero/storage/NKVPDAHN/Ward - Stimulus Information and Sequential Dependencies i.pdf:application/pdf},
}

@article{andeol_sound_2013,
	title = {Sound localization in noise and sensitivity to spectral shape},
	volume = {304},
	issn = {03785955},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378595513001445},
	doi = {10.1016/j.heares.2013.06.001},
	abstract = {Individual differences exist in sound localization performance even for normal-hearing listeners. Some of these differences might be related to acoustical differences in localization cues carried by the head related transfer functions (HRTF). Recent data suggest that individual differences in sound localization performance could also have a perceptual origin. The localization of an auditory target in the up/down and front/back dimensions requires the analysis of the spectral shape of the stimulus. In the present study, we investigated the role of an acoustic factor, the prominence of the spectral shape (“spectral strength”) and the role of a perceptual factor, the listener’s sensitivity to spectral shape, in individual differences observed in sound localization performance. Spectral strength was computed as the spectral distance between the magnitude spectrum of the HRTFs and a ﬂat spectrum. Sensitivity to spectral shape was evaluated using spectral-modulation thresholds measured with a broadband (0.2e12.8 kHz) or highfrequency (4e16 kHz) carrier and for different spectral modulation frequencies (below 1 cycle/octave, between 1 and 2 cycles/octave, above 2 cycles/octave). Data obtained from 19 young normal-hearing listeners showed that low thresholds for spectral modulation frequency below 1 cycle/octave with a high-frequency carrier were associated with better sound localization performance. No correlation was found between sound localization performance and the spectral strength of the HRTFs. These results suggest that differences in perceptual ability, rather than acoustical differences, contribute to individual differences in sound localization performance in noise.},
	language = {en},
	urldate = {2023-12-30},
	journal = {Hearing Research},
	author = {Andéol, Guillaume and Macpherson, Ewan A. and Sabin, Andrew T.},
	month = oct,
	year = {2013},
	pages = {20--27},
	file = {Andéol et al. - 2013 - Sound localization in noise and sensitivity to spe.pdf:/Users/paulfriedrich/Zotero/storage/3UC6Z8CL/Andéol et al. - 2013 - Sound localization in noise and sensitivity to spe.pdf:application/pdf},
}

@article{reiss_spectral_2005,
	title = {Spectral {Edge} {Sensitivity} in {Neural} {Circuits} of the {Dorsal} {Cochlear} {Nucleus}},
	volume = {25},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4963-04.2005},
	doi = {10.1523/JNEUROSCI.4963-04.2005},
	abstract = {One possible function of the dorsal cochlear nucleus (DCN) is discrimination of head-related transfer functions (HRTFs), spectral cues used for vertical sound localization. Recent psychophysical and physiological studies suggest that steep, rising spectral edges may be the features used to identify HRTFs. Here we showed, using notch noise and noise band stimuli presented over a range of frequencies, that a subclass of DCN type IV neurons responded with a response peak when the rising spectral edge of a notch or band was aligned near best frequency (BF). This edge sensitivity was correlated with weak or inhibited responses to broadband noise and inhibition in receptive fields at frequencies below BF. Some aspects of the inhibition shaping the response peak, namely inhibition to rising edges below BF and to falling edges at BF, could be explained by the properties of type II interneurons with BFs below those of the type IV neurons. However, many type IV neurons also showed inhibitory responses with the rising spectral edge just above BF, and these responses could not be reproduced by current models of DCN circuitry. Therefore, a new component of the DCN circuit is needed to fully explain the responses to rising spectral edges. This shaping of edge sensitivity by inhibition to rising spectral edges both below and above BF suggests the specialization of DCN for spectral edge coding along the tonotopic gradient.},
	language = {en},
	number = {14},
	urldate = {2024-01-11},
	journal = {The Journal of Neuroscience},
	author = {Reiss, Lina A. J. and Young, Eric D.},
	month = apr,
	year = {2005},
	pages = {3680--3691},
	file = {Reiss and Young - 2005 - Spectral Edge Sensitivity in Neural Circuits of th.pdf:/Users/paulfriedrich/Zotero/storage/EZDFQZTY/Reiss and Young - 2005 - Spectral Edge Sensitivity in Neural Circuits of th.pdf:application/pdf},
}

@article{langendijk_contribution_2002,
	title = {Contribution of spectral cues to human sound localization},
	volume = {112},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/112/4/1583/550090/Contribution-of-spectral-cues-to-human-sound},
	doi = {10.1121/1.1501901},
	abstract = {The contribution of spectral cues to human sound localization was investigated by removing cues in 12-, 1- or 2-octave bands in the frequency range above 4 kHz. Localization responses were given by placing an acoustic pointer at the same apparent position as a virtual target. The pointer was generated by filtering a 100-ms harmonic complex with equalized head-related transfer functions (HRTFs). Listeners controlled the pointer via a hand-held stick that rotated about a fixed point. In the baseline condition, the target, a 200-ms noise burst, was filtered with the same HRTFs as the pointer. In other conditions, the spectral information within a certain frequency band was removed by replacing the directional transfer function within this band with the average transfer of this band. Analysis of the data showed that removing cues in 12-octave bands did not affect localization, whereas for the 2-octave band correct localization was virtually impossible. The results obtained for the 1-octave bands indicate that up–down cues are located mainly in the 6–12-kHz band, and front–back cues in the 8–16-kHz band. The interindividual spread in response patterns suggests that different listeners use different localization cues. The response patterns in the median plane can be predicted using a model based on spectral comparison of directional transfer functions for target and response directions.},
	language = {en},
	number = {4},
	urldate = {2024-01-13},
	journal = {The Journal of the Acoustical Society of America},
	author = {Langendijk, Erno H. A. and Bronkhorst, Adelbert W.},
	month = oct,
	year = {2002},
	pages = {1583--1596},
	file = {Langendijk and Bronkhorst - 2002 - Contribution of spectral cues to human sound local.pdf:/Users/paulfriedrich/Zotero/storage/ZH3HR2W8/Langendijk and Bronkhorst - 2002 - Contribution of spectral cues to human sound local.pdf:application/pdf},
}

@article{davis_auditory_2003,
	title = {Auditory {Processing} of {Spectral} {Cues} for {Sound} {Localization} in the {Inferior} {Colliculus}},
	volume = {4},
	issn = {1525-3961, 1438-7573},
	url = {http://link.springer.com/10.1007/s10162-002-2002-5},
	doi = {10.1007/s10162-002-2002-5},
	abstract = {The head-related transfer function (HRTF) of the cat adds directionally dependent energy minima to the amplitude spectrum of complex sounds. These spectral notches are a principal cue for the localization of sound source elevation. Physiological evidence suggests that the dorsal cochlear nucleus (DCN) plays a critical role in the brainstem processing of this directional feature. Type O units in the central nucleus of the inferior colliculus (ICC) are a primary target of ascending DCN projections and, therefore, may represent midbrain specializations for the auditory processing of spectral cues for sound localization. Behavioral studies conﬁrm a loss of sound orientation accuracy when DCN projections to the inferior colliculus are surgically lesioned. This study used simple analogs of HRTF notches to characterize single-unit response patterns in the ICC of decerebrate cats that may contribute to the directional sensitivity of the brain’s spectral processing pathways. Manipulations of notch frequency and bandwidth demonstrated frequency-speciﬁc excitatory responses that have the capacity to encode HRTF-based cues for sound source location. These response patterns were limited to type O units in the ICC and have not been observed for the projection neurons of the DCN. The unique spectral integration properties of type O units suggest that DCN inﬂuences are transformed into a more selective representation of sound source location by a local convergence of wideband excitatory and frequency-tuned inhibitory inputs.},
	language = {en},
	number = {2},
	urldate = {2024-01-13},
	journal = {JARO - Journal of the Association for Research in Otolaryngology},
	author = {Davis, Kevin A. and Ramachandran, Ramnarayan and May, Bradford J.},
	month = jun,
	year = {2003},
	pages = {148--163},
	file = {Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:/Users/paulfriedrich/Zotero/storage/6PAJNQMK/Davis et al. - 2003 - Auditory Processing of Spectral Cues for Sound Loc.pdf:application/pdf},
}
